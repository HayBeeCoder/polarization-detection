{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o_XLty3o2U6_",
    "outputId": "6ba35c7c-6dae-45c3-dae6-c69b8e1fa307",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets wandb scikit-learn imbalanced-learn nlpaug accelerate tqdm\n",
    "# from google.colab import drive\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer,  TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "from datasets import Dataset\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import wandb\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import classification_report\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from pathlib import Path\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZAvz2mSn4NR7",
    "outputId": "4cce09d3-c4b2-4556-d940-21bbadeba895"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_dtXKH9h6yhJ"
   },
   "outputs": [],
   "source": [
    "# ================== CONFIG ==================\n",
    "DATA_PATH = \"subtask3_train_eng.csv\"  # ← YOUR SINGLE FILE HERE\n",
    "\n",
    "\n",
    "# MODEL_NAME = 'Twitter/twhin-bert-base'\n",
    "# MODEL_NAME = \"FacebookAI/xlm-roberta-base\"\n",
    "# MODEL_NAME = \"google/rembert\"\n",
    "# MODEL_NAME = 'distilbert/distilbert-base-multilingual-cased'#@param\n",
    "MODEL_NAME = 'microsoft/mdeberta-v3-base'\n",
    "# MODEL_NAME = 'metabloit/swahBERT'\n",
    "# MODEL_NAME=\"castorini/afriberta_large\"\n",
    "\n",
    "# MODEL_NAME = \"distilbert/distilbert-base-multilingual-cased\"\n",
    "# MODEL_NAME = \"roberta-base\"\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 32\n",
    "ACCUM_STEPS = 2                              # Effective batch size = 64\n",
    "EPOCHS = 10\n",
    "LR = 2e-5\n",
    "WARMUP_RATIO = 0.1\n",
    "VAL_SIZE = 0.20                              # 20% for validation\n",
    "RANDOM_STATE = 42\n",
    "PATIENCE = 3\n",
    "\n",
    "OUTPUT_DIR = Path(\"best\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "label_cols = [\"political\",\t\"racial/ethnic\", \"religious\" ,\t\"gender/sexual\",\t\"other\"]\n",
    "num_labels = len(label_cols)\n",
    "# ==========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zWED6m7YCieE",
    "outputId": "5294fd92-e9a3-4f92-afd5-35920bb31bfb"
   },
   "outputs": [],
   "source": [
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r2oEsqqX-YEp",
    "outputId": "1ed79135-8734-495f-efe4-858677cf7e63"
   },
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "\n",
    "# Load the single labeled file\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"Loaded full dataset: {df.shape}\")\n",
    "\n",
    "# Ensure labels are int\n",
    "for col in label_cols:\n",
    "    df[col] = df[col].astype(int)\n",
    "\n",
    "# Create multi-label stratification column\n",
    "df['num_labels'] = df[label_cols].sum(axis=1)\n",
    "\n",
    "# Stratified train/val split based on number of labels (best we can do for multilabel)\n",
    "train_df, val_df = train_test_split(\n",
    "    df,\n",
    "    test_size=VAL_SIZE,\n",
    "    stratify=df['num_labels'],\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Train: {train_df.shape} | Val: {val_df.shape}\")\n",
    "print(f\"Validation label distribution matches training: {train_df['num_labels'].value_counts(normalize=True).round(3).sort_index().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eTw7dCS29eoQ",
    "outputId": "c858e2c3-10c9-40ee-8483-c3d4ba76b008"
   },
   "outputs": [],
   "source": [
    "# Compute pos_weights ONLY from training set\n",
    "pos_counts = train_df[label_cols].sum().values\n",
    "neg_counts = len(train_df) - pos_counts\n",
    "pos_weights = torch.tensor(neg_counts / pos_counts, dtype=torch.float)\n",
    "\n",
    "print(\"\\nPos weights for BCEWithLogitsLoss:\")\n",
    "\n",
    "for label, w in zip(label_cols, pos_weights.numpy().round(2)):\n",
    "    print(f\"  {label}: {w}\")\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OKSL5E_Z_gMz"
   },
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.texts = df['text'].tolist()\n",
    "        self.labels = df[label_cols].values.astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = tokenizer(\n",
    "            str(self.texts[idx]),\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=MAX_LENGTH,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k, v in encoding.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "train_dataset = TextDataset(train_df)\n",
    "val_dataset = TextDataset(val_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E9SFGXrU_Icg",
    "outputId": "55aa69fd-612d-4cad-bdb0-186b26b1f6df"
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=num_labels,\n",
    "    problem_type=\"multi_label_classification\",\n",
    "    ignore_mismatched_sizes=True\n",
    "\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YAxeyNXV78Zk"
   },
   "outputs": [],
   "source": [
    "# Loss with per-label weighting\n",
    "criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weights.to(device))\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "total_steps = len(train_loader) // ACCUM_STEPS * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(WARMUP_RATIO * total_steps),\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CVLm1DJ37_r5"
   },
   "outputs": [],
   "source": [
    "# =============== Threshold Tuning ===============\n",
    "def find_best_thresholds(model, loader):\n",
    "    model.eval()\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(**inputs)\n",
    "            all_logits.append(outputs.logits.sigmoid().cpu())  # We'll use probabilities for search\n",
    "            all_labels.append(labels.cpu())\n",
    "    probs = torch.cat(all_logits).numpy()\n",
    "    y_true = torch.cat(all_labels).numpy()\n",
    "\n",
    "    # Coarse global search\n",
    "    best_thresh = np.ones(num_labels) * 0.5\n",
    "    best_macro = 0\n",
    "    for base in np.arange(0.2, 0.8, 0.05):\n",
    "        thresh = np.array([base] * num_labels)\n",
    "        preds = (probs > thresh).astype(int)\n",
    "        macro = f1_score(y_true, preds, average='macro', zero_division=0)\n",
    "        if macro > best_macro:\n",
    "            best_macro = macro\n",
    "            best_thresh = thresh.copy()\n",
    "\n",
    "    # Fine-tune per label\n",
    "    thresholds = best_thresh.copy()\n",
    "    for i in range(num_labels):\n",
    "        best_t = thresholds[i]\n",
    "        best_f1 = 0\n",
    "        for t in np.arange(max(0.1, thresholds[i]-0.15), min(0.9, thresholds[i]+0.15), 0.01):\n",
    "            temp_thresh = thresholds.copy()\n",
    "            temp_thresh[i] = t\n",
    "            preds = (probs > temp_thresh).astype(int)\n",
    "            macro = f1_score(y_true, preds, average='macro', zero_division=0)\n",
    "            if macro > best_f1:\n",
    "                best_f1 = macro\n",
    "                best_t = t\n",
    "        thresholds[i] = best_t\n",
    "\n",
    "    final_macro = f1_score(y_true, (probs > thresholds), average='macro', zero_division=0)\n",
    "    print(f\"\\nBest per-label thresholds: {np.round(thresholds, 3)}\")\n",
    "    print(f\"Validation Macro-F1 with tuned thresholds: {final_macro:.4f}\")\n",
    "    return thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Op26lvM4LOgf"
   },
   "outputs": [],
   "source": [
    "LANG = 'swa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "E-hs0UFU8DPN",
    "outputId": "60517454-e4d3-4b28-8d22-f00825f8154a"
   },
   "outputs": [],
   "source": [
    "CURRENT_DATE = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "\n",
    "wandb.init(\n",
    "    project=\"polarization-multilabel\",\n",
    "    name=f\"{LANG}_{MODEL_NAME}_{EPOCHS}_{CURRENT_DATE}\",\n",
    "    config={\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"accum_steps\": ACCUM_STEPS,\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"learning_rate\": LR,\n",
    "        \"warmup_ratio\": WARMUP_RATIO,\n",
    "        \"labels\": label_cols,\n",
    "    }\n",
    ")\n",
    "\n",
    "wandb.log({\n",
    "    f\"pos_weight/{lbl}\": w.item()\n",
    "    for lbl, w in zip(label_cols, pos_weights)\n",
    "})\n",
    "\n",
    "# =============== Training Loop ===============\n",
    "best_macro_f1 = 0\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    progress = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for step, batch in enumerate(progress):\n",
    "        inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(**inputs)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "        loss = loss / ACCUM_STEPS\n",
    "        loss.backward()\n",
    "\n",
    "        if (step + 1) % ACCUM_STEPS == 0:\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "    wandb.log({\n",
    "    \"train/loss\": loss.item() * ACCUM_STEPS,\n",
    "    \"lr\": scheduler.get_last_lr()[0],\n",
    "  })\n",
    "\n",
    "\n",
    "    progress.set_postfix({'loss': loss.item() * ACCUM_STEPS})\n",
    "\n",
    "    # Threshold tuning and evaluation\n",
    "    thresholds = find_best_thresholds(model, val_loader)\n",
    "\n",
    "    for lbl, t in zip(label_cols, thresholds):\n",
    "      wandb.log({f\"threshold/{lbl}\": t})\n",
    "\n",
    "\n",
    "    # Final eval with best thresholds\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "            outputs = model(**inputs)\n",
    "            all_probs.append(outputs.logits.sigmoid().cpu())\n",
    "    probs = torch.cat(all_probs).numpy()\n",
    "    preds = (probs > thresholds).astype(int)\n",
    "    y_true = val_df[label_cols].values\n",
    "\n",
    "    macro_f1 = f1_score(y_true, preds, average='macro')\n",
    "    micro_f1 = f1_score(y_true, preds, average='micro')\n",
    "    wandb.log({\n",
    "    \"val/macro_f1\": macro_f1,\n",
    "    \"val/micro_f1\": micro_f1,\n",
    "})\n",
    "\n",
    "    print(f\"Epoch {epoch+1} → Macro-F1: {macro_f1:.4f} | Micro-F1: {micro_f1:.4f}\")\n",
    "\n",
    "    if macro_f1 > best_macro_f1:\n",
    "        best_macro_f1 = macro_f1\n",
    "        patience_counter = 0\n",
    "        model.save_pretrained(OUTPUT_DIR / \"best_model\")\n",
    "        tokenizer.save_pretrained(OUTPUT_DIR / \"best_model\")\n",
    "        np.save(OUTPUT_DIR / \"best_thresholds.npy\", thresholds)\n",
    "        pd.DataFrame({'label': label_cols, 'threshold': thresholds}).to_csv(OUTPUT_DIR / \"thresholds.csv\", index=False)\n",
    "        print(f\"✓ New best model saved (Macro-F1: {best_macro_f1:.4f})\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING FINISHED\")\n",
    "print(f\"Best Validation Macro-F1: {best_macro_f1:.4f}\")\n",
    "print(f\"Model + tokenizer saved to: {OUTPUT_DIR / 'best_model'}\")\n",
    "print(f\"Optimal thresholds saved to: {OUTPUT_DIR / 'best_thresholds.npy'} and thresholds.csv\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I9iY8f2SIQ--"
   },
   "outputs": [],
   "source": [
    "# ===================== DEV SET INFERENCE (SINGLE CELL) =====================\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# -------- PATHS --------\n",
    "DEV_PATH = \"/content/drive/MyDrive/polarization_dataset/subtask3/dev/swa.csv\"\n",
    "MODEL_DIR = \"best/best_model\"\n",
    "THRESH_PATH = \"best/best_thresholds.npy\"\n",
    "\n",
    "# -------- CONFIG --------\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "label_cols = [\n",
    "    \"stereotype\",\n",
    "    \"vilification\",\n",
    "    \"dehumanization\",\n",
    "    \"extreme_language\",\n",
    "    \"lack_of_empathy\",\n",
    "    \"invalidation\",\n",
    "]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -------- LOAD MODEL / TOKENIZER / THRESHOLDS --------\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "thresholds = np.load(THRESH_PATH)\n",
    "print(\"Loaded thresholds:\", np.round(thresholds, 3))\n",
    "\n",
    "# -------- LOAD DEV DATA --------\n",
    "dev_df = pd.read_csv(DEV_PATH)\n",
    "\n",
    "# FIX: fill missing labels safely\n",
    "dev_df[label_cols] = dev_df[label_cols].fillna(0).astype(int)\n",
    "\n",
    "# -------- DATASET --------\n",
    "class DevDataset(Dataset):\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = tokenizer(\n",
    "            str(self.texts[idx]),\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=MAX_LENGTH,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return {k: v.squeeze(0) for k, v in enc.items()}\n",
    "\n",
    "dev_loader = DataLoader(\n",
    "    DevDataset(dev_df[\"text\"].tolist()),\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "# -------- INFERENCE --------\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dev_loader:\n",
    "        inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "        probs = model(**inputs).logits.sigmoid().cpu().numpy()\n",
    "        all_probs.append(probs)\n",
    "\n",
    "probs = np.vstack(all_probs)\n",
    "preds = (probs > thresholds).astype(int)\n",
    "\n",
    "# -------- EVALUATION --------\n",
    "y_true = dev_df[label_cols].values\n",
    "\n",
    "macro_f1 = f1_score(y_true, preds, average=\"macro\", zero_division=0)\n",
    "micro_f1 = f1_score(y_true, preds, average=\"micro\", zero_division=0)\n",
    "\n",
    "print(f\"DEV Macro-F1: {macro_f1:.4f}\")\n",
    "print(f\"DEV Micro-F1: {micro_f1:.4f}\")\n",
    "\n",
    "# -------- SAVE PREDICTIONS --------\n",
    "pred_df = dev_df[[\"id\"]].copy()\n",
    "for i, lbl in enumerate(label_cols):\n",
    "    pred_df[lbl] = preds[:, i]\n",
    "\n",
    "pred_df.to_csv(\"pred_swa.csv\", index=False)\n",
    "print(\"Saved predictions to dev_predictions.csv\")\n",
    "\n",
    "# ========================================================================\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BjToiGsOKXvZ"
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
